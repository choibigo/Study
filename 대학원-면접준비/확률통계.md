# 정리

## Probability란
- 어떤 일이 일어날 가능성

## Probability Theory란
- Random 사건을 분석하고 설명하는 학문

## Statistics
- Random한 Data로 부터 유의미한 결과를 얻어내는 학문

## 확률 VS 통계
- 확률은 모델이 주어져 있고 Data를 예측하는 것이고, 통계는 Data가 주어져 있고 모델을 예측하는 것이다.
- 확률은 어떤 사건이 일어날 수 있는 수학적 기대치 이고, 통계는 이미 발생한 Data를 통해 앞으로 발생할 사건을 파악하는 것이다.

## Sample Space 
- 어떤 사건의 경우를 모두 모아놓은 집합

## Countable 이란
- 집합의 개수가 유한 한것
- 집합의 개수가 무한 하더라도 자연수와 1대1 대응이 가능한 경우(나열이 가능한경우)
- 자연수, 정수, 유리수 => Countable
- 실수 => Uncountable

## Discrete Probability VS Continous Probability
- Sample Space가 Countable 하면 Discrete이고 Uncountable 하면 Continous이다.

## Conditional Probability 란
- 어떤 사건이 발생한 이후 다른 사건이 발생할 확률

## Marginal Distribution
- 두개의 확률 변수가 있을때 하나의 확률 변수만의 확률분포를 고려하는 경우

## Independent란?
- 어떤 사건이 발생해도 다른 사건에 영향을 미치지 못하는 경우

## Baye's Theorem
- 두 확률 변수의 사전확률과 사후 확률 사이의 관계를 나타내는 정리
- 사전 확률로 부터 사후확률을 구할 수 있다.
![image](https://github.com/choibigo/Study/assets/38881179/e1f695bb-a5b2-4604-bd6f-720307dae89e)
- P(A)는 사전 확률, P(A|B)는 A의 사후 확률이다.
- 베이지안 최적화를 통해 하이퍼파라미터를 효율적으로 찾아낼 수 있다.

## Random Variable이란
- 특정 사건 Sample Space를 실수에 대응 시켜주는 어떠한 함수 이다.
- 이때 Range는 대응 하는 모든 실수의 집합 이다.

## Bernoulli Distribution
- 어떤 실험이 성공, 실패가 있을때 성공시 p, 실패시 1-p의 확률을 따르는 분포이다.

## Binomial Distribution
- 어떠 실험을 n번 했을때 각 시행의 성공이 p의 확률을 가질때의 이산 분포 이다.
![image](https://github.com/choibigo/Study/assets/38881179/558e9f0c-17ea-4800-b558-7909c5050522)

## Geometric Distribution
- 베르누이 분포에서 처음 성공할 때 까지의 실행 횟수를 확률변수 x라고 할때, 이를 Geometric Distribution이라 한다.
![image](https://github.com/choibigo/Study/assets/38881179/e27e210a-2d2d-42c4-8238-4436469928c2)

## Pascal Distribution
- 총 M개의 성공을 볼때까지의 실행 횟수를 X라고 할때, 이를 Pascal Distrubtion 이라한다.

## Poisson Distrubtion
- 사건의 가능성이 다양하고 각 사건의 확률이 작을때 사용한다.

## Uniform Distribution
- 특정 구간에서 동일한 확률을 갖는 분포이다.
- 평균 : (b+a)/2, 분산 : (b-a)^2/ 12

## Normal Distribution
- 평균과 분산이 주어졌을때 나타낼 수 있는 분포형태로, 평균을 중심으로 종 형태로 그래프 모양이 나타난다.
- 이때 평균이 0, 분산이 1인 정규 분포를 표준정규분포 라고 한다.

## Joint Probability
- 확률 변수가 2개인 PMF이다.
- Joint PMF에서 하나의 확률 변수를 모두 더해 Marginal PMF를 구할 수 있다.

## Covariance
- 2개의 확률 변수의 선형 관계를 나타내는 값
- 양수 일때 : 비례 관계
- 음수 일때 : 반비례 관계
- 0일떄 : 관계 없음(두 확률 변수가 독립이다.)
- 값이 크다고 큰 관계를 갖는 것은 아니다. 데이터 단위에 따라서 범위가 변할 수 있다.

## Correlation Coefficient
- Covariance의 범위는 정해져 있지 않다. 상관 계수는 확률 변수간의 관계를 수치화 한것이다.
- covariace를 각 확률 변수의 표준편차의 곱으로 나눈 값이다.
- -1 ~ 1사이 값을 가지며 값의 크기가 관계의 정도를 나타내지는 않는다.

## Momentum Generate Function 이란
- 미분함수를 통해 Momentum을 구할수 있는 함수이다.
- Momentum이란 확률변수의 n 제곱의 기댓값이다.
- MGF 함수가 동일 하다면 그 함수의 분포는 동일하다고 판단할 수 있다.

## IID
- Independent Inequality Distribution의 약자로 서로 독립이면서 동일한 확률 분포를 가진 확률분포간의 관계를 의미한다.
- IID의 중요한 점은 IID인 분포들은 중심극한정리를 이용할수 있다는 것이 중요하다.

## Characteristic Function
- MGF는 기댓값이 정의 될 때만 사용가능하다.
- 그러나 Characteristic Function은 기댓값이 정의 되지 않아도 미분을 통해 Momentum을 구할 수 있는 함수이다.
- 미분을하면 복소수의 n제곱과 같이 나온다.

## Weak Law of Large Number
- 확률에는 논리적으로 계산할 수 있는 수학적 확률과 측정을 통해 얻을수 있는 통계적 확률이 있다.
- 통계적 확률을 측정할 때 측정하는 횟수가 많아지면 통계적 확률이 수학적 확률에 수렴한다는 법칙이다.

## Central Limit Theorem
- IID 인 여러 분포의 확률변수들의 Normalized Average한 확률 변수는 뽑은 개수가 많아 질수록 즉, 무한개로 갈수록 Normal Distribution에 수렴한다 라는 이론이다.
- 수집된 표변의 통계량을 통해 모집단의 파라미터를 추정할 수 있는 확률적 근거가 된다.

## Estimate, Estimator
- Estimate는 추정값이다, 예를 들어 Sample Mean이 있다.
- Estimator는 실제값이다.

## Bias
- Estimate의 기댓값에 실제값인 Estimator를 뺸 값의 크기를 보고 판단한다.
- 만약 그값이 0 이라면 Unbiased 되있다고 하고 그렇지 않다면 Biased되있다고 한다.
- 이를통해 얼마나 잘 추정했나를 판단할 수 있다.

## MSE
- Bias에는 측정 개수가 1이여도 0으로 나타날 수 있는 문제점이 있다 이를 보완할때 사용하는 측정방법이다.
- Estimate에서 Estimator를 뺀 제곱의 기댓값을 구하는 것이다. 이는 Decomposition 할 수 있는 데 Estimate의 분산 더하기 Bias의 제곱으로 표현가능하다.
- 이를통해 Bias의 단점을 보완할 수 있다.
- 이때 MLE를 줄이는 방법으로 Bias를 0으로 만들면서 분산을 작게하는 방법도 있지만 Bias가 0이아니더라도 분산을 줄이는 방법으로 MLE를 줄일수 있다.
- 이처럼 MLE에서는 Bias와 분산이 Trade Off 관계에 있다.

## Consistent Estimate
- Estimate에서 Estimator를 뺸 절대값이 입실론 보다 클 확률이 0일때 Consistent라고 하며
- Estimate와 Estimator를 동일하게 일관적으로 사용할수 있다라고 판단 가능하다.

## Good Estimate
- Bias값이 0
- Consistent 값이 0 
- MLE가 작을 수록 좋다.

## MLE
- Measurement가 있을떄, 이 Measurement가 나오기 위한 조건들은 여러가지 있다. 이떄 이 조건들에 대한 확률 분포를 Liklihood 라고 할수 있다.
- 이때 Liklihood가 가장 큰 즉 Measurement가 나오기 위한 확률이 가장큰 조건을 찾는 것이 MLE이다.
- Liklihood Function을 1차 미분, 2차 미분을 통해 가장 큰 위치를 실제로 구할 수 있다.

## MAP
- MLE에서 Prior Distribution 즉, 조건 차제의 분포를 알 떄 사용할 수 있다.
- 그러나 그 분포가 정확하지 않다면 MLE보다 성능이 낮아질 수 있다.

## confidence Interval
- 모수가 있을것이라 추정되는 구간