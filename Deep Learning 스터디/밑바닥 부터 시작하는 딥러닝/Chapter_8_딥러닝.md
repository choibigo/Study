## 8.1 더 깊게

## 8.1.1 더 깊은 신경망으로
![image](https://velog.velcdn.com/post-images%2Fdscwinterstudy%2Fbb9c3a30-4192-11ea-82e0-f10b8886fb3a%2F%EC%86%90%EA%B8%80%EC%94%A8%EC%8B%AC%EC%B8%B5CNN.png)

- 3X3 크기의 필터로, 층이 깊어지면서 채널 수가 더 늘어나는 것이 특징이다.
- 풀링 계층을 추가해 중간 데이터의 공간 크기를 점차 줄여 나간다.
- 마지막 단의 완전 연결 계층에서 드롭아웃 계층을 사용한다.
  - 입력 데이터와 가중치가 1대 1로 대응하는 것을 완전 연결 이라 한다.
- Optimizer는 Adam을 사용
- 가중치 초기 값은 "He" 초기 값

## 8.1.2 정확도를 더 높이려면
- 앙상블 학습, 학습률 감소, 데이터 확장 등이 정확도 향상에 공헌하고 있다.
- Data Augmentatino은 입력 이미지를 알고리즘을 이용해 인위적으로 확장한다.
- 미세한 변화를 주어 학습 이미지 개수를 늘리는 것이다.
- 훈련 이미지의 개수를 늘릴 수 있다면 딥러닝 인식 수준을 개선 할 수 있다.

## 8.1.3 깊게 하는 이유
- 깊게 하는것이 왜 중요 한가에 대한 이론적인 근거는 아직 많이 부족하다.
- 층을 깊게 한 신경망은 깊지 않는 경우보다 적은 매개 변수로 같은 수준의 표현력을 달성할 수 있다.
![image](https://velog.velcdn.com/post-images%2Fdscwinterstudy%2Fd4af9990-4192-11ea-bf7e-239e36e1bc11%2F5by5%ED%95%A9%EC%84%B1%EA%B3%B1.png)
- 각각의 출력 노드는 입력데이터의 5X5 크기 영역에서 계산 된다.
- "개"를 인식 할때 얕은 신경망에서 해결 하려면, 합성곱 계층은 개의 특징을 대부분 한번에 "이해" 해야 한다.
- 견종도 다양하고 어느 각도에서 찍은 사진이냐 따라 완전히 다르게 보일 수 있다.
- 개의 특징을 이해하려면 변화가 풍부하고 많은 학습 데이터가 필요하고, 결과적으로 학습 시간이 오래걸린다.

![image](https://velog.velcdn.com/post-images%2Fdscwinterstudy%2Fd9594b80-4192-11ea-b7ab-b932b78555b8%2F3by3%ED%95%A9%EC%84%B1%EA%B3%B1.png)
- 3X3 합성곱 연산을 2회 반복하는 경우
- 출력 데이터는 중간 데이터의 3x3 영역에서 계산 된다. 중간 데이터는 입력데이터 5x5 크기의 영역에서 계산되어 나오는 것을 알 수 있다.
- 작은 필터를 겹쳐 신경망을 깊게 할 때의 장점은 매개변수 수를 줄여 넓은 수용영역을 소화할 수 있다는데 있다.
- 층을 거듭 하면서 활성화 함수를 계층 사이에 끼움으로써 신경망에 비선형적인 힘을 가하고 더 복잡한 것도 표현할 수 있게 해준다.
- 신경망을 깊게 하면 학습해야할 문제를 계층적으로 분해 할 수 있다.
- 각 층이 학습해야할 문제를 단순한 문제로 대체 할 수 있다.
- 처음 층은 에지 학습에만 전념하여 적은 학습 데이터로 효율적으로 학습 할 수 있다.

## 8.2 대표적인 신경망

## 8.2.2 VGG
- vgg는 합성곱 계층과 풀링 계층으로 구성된 기본적인 CNN 이다.
- 합성곱 계층, 완전 연결 계층 을 모두 16층 또는 19 층으로 심화한게 특징이다.
- 3x3 의 작은 필터를 사용한 합성곱 계층을 연속으로 거친다.
- 합성곱 계층을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리를 반복하고 마지막에는 완전연결 계층을 통과시켜 결과를 출력한다.

## 8.2.3 GoogLeNet
![image](https://blog.kakaocdn.net/dn/Iq9NO/btqyPWk5PBX/K2JicGjIjj5w0eFIbhx4bK/img.png)
- GoogLeNet은 가로 방향에 **폭** 이 있다, 이를 **인셉션 구조**라고 한다.
![image](https://velog.velcdn.com/post-images%2Fdscwinterstudy%2F8556b550-419b-11ea-a3b8-fd5b14e3378a%2F%EA%B5%AC%EA%B8%80%EB%84%B7%EC%9D%B8%EC%85%89%EC%85%98.png)
- 크기가 다른 필터(와 풀링)을 여러개 적용하여 그 결과를 결합한다.
- 이 구조를 하나의 블록으로 사용한다.
- 또 1x1 크기의 필터를 사용한 합성곱 계층을 많은 곳에서 사용하여 채널의 크기를 줄여 매개 변수 제거와 고속 처리에 기여 한다.

## 8.2.4 ResNet
- 딥러닝 학습에서 층이 지나치게 깊으면, Gradient Vanishing같은 문제 떄문에 학습이 잘 되지 않고 오히려 성능이 떨어지는 경우가 많았다.
- 그런 문제를 해결하기 위해 Skip Connection을 도입 한다.
- 이 구조가 층의 깊이에 비례해 성능을 향상시킬 수 있게한 핵심이다.
![image](https://velog.velcdn.com/post-images%2Fdscwinterstudy%2Ffb4e1da0-4193-11ea-9037-c1df5ac05aa2%2FResNet.png)
- 입력 x를 연속한 두 합성곱 계층을 건너 뛰어 출력에 바로 연결 한다.
- 이결과 출력을 F(x) + x 가 되는게 핵심이다.
- 이는 역전파 때 스킵 연결이 신호를 감쇠를 막아주기 때문이다.
  - 역전파 떄도 상류의 기울기를 그대로 하류로 보낸다. 따라서 기울기가 작아지거나 지나치게 커질 걱정이 없다.

## 8.3 딥러닝 가속화
- 최근 프레임워크에서는 학습을 복수의 GPU와 여러 기기로 분산 수행 한다.

## 8.3.1 풀어야 할 숙제
- 순전파 에서 Convolution 계층이 90% 이상을 차지 한다.
- 합성곱 계층에서 이뤄지는 연산을 어떻게 고속으로 처리하느냐가 딥러닝의 과제 이다.

## 8.3.2 GPU를 활용한 고속화
- GPU는 병렬 수치 연산을 고속으로 처리할 수 있다.
- 딥러닝에서는 단일 곱셈-누산 을 수행한다, 이러한 연산은 GPU가 특화되어 있다.

## 8.3.3 분산 학습
- 딥러닝 계산을 더욱 고속화하고자 다수의 GPU와 기기로 계산을 분산한다.

## 8.3.4 연산 정밀도와 비트 줄이기
- 메모리 용량 면에서 대량의 가중치 매개변수와 중간 데이터를 메모리에 저장해야 한다는 것을 생각 해야 한다.
- 버스 대역폭 면에서도 버스를 흐르는 데이터가 많아져 병목 현상이 일어날 수 있다.
- 이를 해결하기 위해서 네트워크로 주고받는 데이터의 비트 수를 최소로 만들어야 한다.
- 딥러닝은 높은 수치 정밀도를 요구하지는 않는다.(이미지에 노이즈가 섞여 있어도 출력 결과가 잘 달라지지 않는 현상과 같은 맥락)
- 따라서 딥러닝은 16비트 반정밀도만 사용해도 학습에 문제가 없다.

## 8.4 딥러닝 활용

## 8.4.1 사물 검출
- 사물 검출은 같은 이미지 속에 담긴 사물의 위치와 종류(클래스)를 알아내는 기술이다. 
- 사물 검출 문제에 CNN을 기반으로 한 기법이 몇가지 제안된다.
![image](https://velog.velcdn.com/post-images%2Fdscwinterstudy%2F0b0c6b70-4194-11ea-9037-c1df5ac05aa2%2Frcnn.png)
- 먼저 사물이 위치한 영역을 찾아내고, 추출한 영역에 CNN을 적용하여 클래스를 분류 한다.

## 8.4.2 Segmentation
- 분할 이란 이미지를 픽셀수준에서 분류하는 문제이다.
- 픽셀 단위로 객체마다 채색된 Map 데이터를 사용해 학습 한다.
![image](https://velog.velcdn.com/post-images%2Fdscwinterstudy%2F1c242ec0-4194-11ea-9037-c1df5ac05aa2%2F%EB%B6%84%ED%95%A0.png)
- 모든 픽셀 수만큼 forward처리를 한다면 시간이 오래 걸린다.
![image](https://velog.velcdn.com/post-images%2Fdscwinterstudy%2F4082f170-4194-11ea-82e0-f10b8886fb3a%2Ffcn.png)
- Fully Convolution Network 를 이용해 한번의 forward처리로 모든 픽셀의 클래스를 분류해주는 기법이다.
- 일반적인 CNN이 완전 연결계층을 이용하는 반면, FCN은 완전연결 계층을 "같은 기능을 하는 합성곱 계층"으로 바꾼다.
- FCN에서는 1차원으로 변환하지 않고 공간 볼륨을 유지한 채 마지막 출력을 처리할 수 있다.
- 마지막에 공간 크기를 확대하는 처리르 도입했다.
- 이 확대 처리로 줄어든 중간 데이터를 입력 이미지와 같은 크기까지 확대 할 수 있다.