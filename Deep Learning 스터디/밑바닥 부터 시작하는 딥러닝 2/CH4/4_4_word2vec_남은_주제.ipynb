{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 word2vec 남은 주제\n",
    "\n",
    "#### 4.4.1 word2vec을 사용한 애플리케이션 예\n",
    "- 자연어 처리 분야에서 단어의 분산 표현이 중요한 이유는 Transfer Learning에 있다.\n",
    "- 전이 학습은 한 분야에서 배운 다른 지식을 다른 분야에도 적용하는 기법이다.\n",
    "- 큰 corpus로 미리 학습된 모델을 적용하고자 하는 도메인 데이터로 다시 학습 시키는 것이다.\n",
    "- 단어의 분산 표현은 단어를 고정 길이 벡터로 변환해준다는 장점도 있다.\n",
    "- 게다가 문장(단어의 흐름)도 단어의 분산 표현을 사용하여 고정 길이 벡터를 변환할 수 있습니다.\n",
    "- 문장을 고정 길이 벡터로 변환하는 가장 간단한 방법은 문장의 각 단어를 분산 표현으로 변환하고 그 합을 구하는 것이다, 이를 bag-of-word라고 한다.\n",
    "- 이는 단어의 순서를 고려하지 않은 방법이다.\n",
    "- RNN을 사용하면 단어의 순서를 고려할 수 있다.\n",
    "- 자연어를 벡터로 변환할 수 있다면 일반적인 머신러닝 기법을 적용할 수 있기 때문이다.\n",
    "\n",
    "#### 메일 자동 분류 시스템\n",
    "- 메일을 수집하여 데이터를 확보 할 수 있다.\n",
    "- 메일에 대해 레이블링 작업을 하여 word2vec을 이용해 메일을 벡터로 변환 한다.\n",
    "- 이후 어떤 분류 시스템(SVM, 신경망 등)을 이용하여 메일에 대한 감정을 분류 할 수 있게 된다.\n",
    "- 이 예처럼 자연어를 다루는 문제는 단어의 분산 표현이라는 방법으로 벡터화할 수 있다.\n",
    "- 이를 통해 일반적인 머신러닝 기법으로 자연어를 다룰 수 있게 됬다.\n",
    "\n",
    "#### 4.4.2 단어 벡터 평가 방법\n",
    "- 단어의 분산 표현은 메일 감정 분석과 같이 특정한 애플리케이션에서 사용되는 것이 대부분 이다.\n",
    "- 단어의 분산 표현을 만드는 시스템과 특정 문제애 대해 분류하는 시스템 처럼 여러 시스템(네트워크)로 구성될 것이다.\n",
    "- 단어의 분산 표현시스템과 분류하는 시스템의 학습을 따로 할 수 도 있다.\n",
    "- 그 경우 단어의 분산 표현의 차원수가 최종 정확도에 어떤 영향을 주는지 조사하려면, 단어의 분산 표현을 학습하고, 그 분산 표현을 머신러닝 시스템으로 분류하도록 학습해야한다.\n",
    "- 두 단계의 학습을 수행한 다음 평가해야할 것이다, 또한 두 시스템 각각에서 최적의 하이퍼파라미터를 찾기위한 튜닝도 필요하다.\n",
    "- 이 때문에 시간이 오래 걸릴 수 있따.\n",
    "- 그래서 단어의 분산 표현의 우수성을 실제 애플리케이션과는 분리해 평가하는 것이 일반적이다 ( 단어 분산 표현 방법은 평가의 대상이 되지 않나봄, 잘 되었다고 가정하에 시스템 구성 하나 봄)\n",
    "- 이떄 사용되는 분산 표현의 평가 척도가 '유사성'이나 '유추 문제'를 활용한 평가이다.\n",
    "- 'cat'과 'animal'의 유사도는 8점 'car'과 'cat'의 유사도는 2점과 같이 단어사이의 유사한 정도를 규정한다.\n",
    "- 그리고 사람이 부여한 점수와 word2vec에 의한 코사인 유사도 점수를 비교해 그 상관것을 보는 것이다.\n",
    "- 유추문제는 \"king : queen = man : ?\"과 같은 유추 문제를 출제하고 단어의 분산 표현의 우수성을 측정한다.\n",
    "- \"king:queen = actor:actress\"와 같이 단어의 Semantic를 묻는 문제, \"bad:worst = good:best\"와 같이 syntax를 묻는 문제가 있다.\n",
    "- 유추 문제를 이용하면 단어의 의미나 문법적인 문제를 제대로 이해 하고 있는 지를 측정할 수 있다.\n",
    "\n",
    "## 4.5 정리\n",
    "- word2vec 고속화를 주제로 CBOW 모델을 개선했다.\n",
    "- Embedding 계층을 구현하여 행렬 연산량을 줄였다.\n",
    "- 전체 데이터를 고려하는 softmax를 대신해 Negative Sampling을 도입해 연산량을 줄였다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
