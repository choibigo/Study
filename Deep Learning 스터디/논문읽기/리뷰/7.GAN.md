# Generative Adversarial Network
- Genreative와 Discriminator가 서로 대립하며 서로의 성능을 점차 개선해가며 학습하는 방법

## GAN의 구조와 원리
<br>

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdsLkY2%2FbtqDx6ibwSp%2FFKgJojS3w2gsh9EP1XYVuK%2Fimg.png)
<br>

#### Generator(생성자)
- 생성된 **Z** 를 받아서 실제 데이터와 비슷한 데이터를 만들어내도록 학습
- 노이즈를 입력으로 받아 다수의 층을 통과하면서 특징 맵을 확장시켜나가는 구조로 이루어져 있다.
- 마지막 층을 통과해서 나오는 특징맴은 이미지 크기와 같다.

#### Discriminator(구분자)
- 실제 데이터와 생성자가 생성한 가짜 데이터를 구별하도록 학습
- 특징맵의 크기를 줄여 나가는 구조로, 전통적인 인공신경망의 구조를 따르고 있다.

#### 손실함수
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdo2VM7%2FbtrrKIzYQxX%2FggLoXmWqqPtmeWSNPsyEu1%2Fimg.png)
- x : 진짜 데이터
- z : 가짜 데이터(노이즈)
- D() : Discrimintor 결과 값(값이 클수록 진짜라 판단)
- G() : Generator 결과, 랜덤 노이즈를 입력 받아 가짜 이미지를 생성 한다.
- X~Pdata(x) : 실제데이터에서 샘플링한 데이터 
- Z~PZ(Z) : 정규분포를 사용하는 임의의 노이즈에서 샘플링한 데이터(Latent Vector), Z는 단순하고 균등 분포나, 정규 분포에서 무작위로 추출된 값이다.
- Discriminator는 위 손실함수의 값을 최대화 시켜야 한다.
  - 진짜 데이터를 판단하는 D(x)의 값은 1에 가까워야 한다.
  - 가짜 데이터를 판단하는 D(G(Z))의 값은 0에 가까워야 한다.
  - 그 결과 Discriminator는 최대화 해야 한다. 
- Generator는 위 손실함수의 값을 최소화 시켜야 한다.
  - D(G(Z)) = 1이 될때 즉, Discriminator가 가짜 데이터를 진짜라고 판단할때

## GAN의 학습

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbRwvnH%2FbtqDzkNAl8w%2FxRJmkKhyZLCATOxU6nMk2K%2Fimg.png)
- 검정 : Real 데이터 확률 분포
- 초록 : Generator 확률 분포
- 파랑 : Dscriminator 확률 분포
- Discriminator는 Generator와 기존 확률 분포가 얼마나 다른지 판단한다.
- Generator는 Real 확률분포에 맞춰 Discriminator를 속이기 위한 쪽으로 모델을 학습한다.
- 궁극 적으로 Generator의 확률 분포가 Real 데이터의 확률 분포와 차이를 줄여 나가는 과정을 거치게 된다.
- 최종 결과 Discriminator의 정확도는 50% (진짜와 가짜 판단 불가능)가 된다.

## GAN의 추론
- GAN은 입력이 특정 이미지, 형식이 아닌 **랜덤 벡터**이다.
- 그렇기 때문에 추론시 랜덤 벡터가 입력이기 때문에 결과 이미지가 학습된 데이터 셋(0~10 사이 숫자 이미지) 중 어떤 이미지가 생성될지 모른다.
- 특정 이미지나 형식으로 추론 하는 방식 ex) "1" =>  1이미지 생성 은 Pix2Pix 나 CycleGAN 으로 가능하다.