# DeepLab 히스토리

#### DeepLab V1
- Atrous Convolution 처음 사용

#### DeepLab V2
- Multi-Scale Context를 적용하기 위한 Atrous Spatial Pyramid Pooling 제안

#### DeepLab V3
- 기존 ResNet 구조에 Atrous Convolution을 활용해 좀더 Dense한 Feature Map을 얻는 방법을 제안

#### DeepLab V3+
- Deepwise Separable Convolution과 Atrous Convolution을 결합한 Atrous Separable Convolution 제안


# DeepLabv3+의 주요 특징

## Atrous Spatial pyramid Pooling 

#### Atrous Convoltuion
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbItUtl%2FbtqBJ8hWdUH%2F6j5GXxftyLthsLOQg5MULk%2Fimg.png)
- Atrous에서 trous는 구멍을 의미 한다.
- Atrous Convolution은 기존 Convolution과 다르게 필터 내부에 빈 공간을 둔 채 작동 한다.
- 파라미터 r(rate)를 통해 빈공간의 크기를 결정한다. (1인 경우 기존 Convolution과 동일)
- 기존 Convolution과 동알한 양의 파라미터와 계산량을 유지 하면서도, Fiedl Of View(FOV)를 더 크게 가져갈 수 있다.
- 기존 Convolution 연산을 사용하면 디테일한 정보가 줄어 들고 특성이 점점 추상화 된다.  이를 Segmentation에서 그대로 사용하기엔 어렵다. Atrous Convolution을 사용하면 FOV를 넓이는 반면에 Feature의 추상화를 방지할 수 있다.

#### Atrous Spatial Pyramid Pooling
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FmhtXE%2FbtqBLjQ2VRk%2FsAfnwSpiK33J0KiczzCOI1%2Fimg.png)
- Semantic Segmentation의 성능을 높이기 위한 방법으로 Spatial Pyramid Pooling 기법이 자주 사용된다.
- DeepLab V2에서 Feature Map으로부터 Rate가 다른 Atrous Convolution을 병렬로 적용한 뒤, 이를 다시 합쳐주는 ASPP기법을 활용할 것을 제안했다.

#### Spatial Pyramid Pooling
- 특정 Pooling 과정을 통과하면 사이즈가 다른 Region Proposal들을 고정된 사이즈의 벡터들로 변환하는 과정이다.
- 서로 다른 이미지의 크기를 고정된 크기로 변환하는 기법이다.
- 다양한 스케일의 피처를 풀링할 수 있어 객체 탐지의 정확도가 높아 진다.

## Depthwise Separable Convolution

#### 기존 Convolution
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FqsrRP%2FbtqBJe3NaHj%2FgeEfeCGQtJvZpWOxxO4ka1%2Fimg.png)
- 입력 이미지가 8X8X3 이고 필터하나의 크기가 3X3 입력 채널이 3이기 때문에 필터의 파라미터 개수는 3X3X3=27개가 된다.
- 입력값: 8X8X3
- 필터 크기: 3X3, 필터 개수: 16
- 파라미터 개수: 3X3X3X16 = 432개

#### Deepthwise Convolution
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcUy5sc%2FbtqBM7JndBq%2Fi9NAStdtqek2wshzQz5EXk%2Fimg.png)
- Convolution 연산에서 채널 축을 필터가 한번에 연산하는 대신 입력의 Channel을 모두 분리 하고 Channel이 1인 여러개의 Convolution 필터로 대체시킨 연산을 Depthwise Convolution 이라 한다.
- Depthwise Convolution으로 나온 결과에 대해 1X1XC의 크기의 Convolution 필터를 적용한 것을 Depthwise Separable Convolution 이라 한다.
- 기존 Convolution 필터가 Sepatial Dimension과 Channel Dimension을 동시에 처리하던 것을 따로 분리시켜 각각 처리 한다.
- 이러한 연산을 수행하는 이유는 기존 Convolution 과 유사한 성능을 보이면서도 사용되는 파라미터의 수를 획기적으로 줄일 수 있다.
- 여러개의 필터가 Spatial Dimension 처리에 필요한 파라미터를 하나로 공유함으로써 파라미터의 수를 더 줄일 수 있게 됬다.
- 두 축을 
- 입력값: 8X8X3
- 필터 크기: 3X3, 필터 개수: 16
- 파라미터 개수: 3X3X3 + 3X16 = 75개
- 필터크기 X 채널수 + 채널수X필터의 크기, 각채널별로 convolution한 결과를 1X1XC크기의 Convoltuion 필터를 필터 개수(16)만틈 적용

## Encoder Decoder Structure
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FzoXGV%2FbtrlYQ3RA7d%2FUKo5h9eVikDKY8h4EdcbgK%2Fimg.png)
- Encoder Decoder 구조를 사용하기 때문에 추출된 정보를 가지고 Segmentation을 진행할 시, 물체의 경계가 모호하지 않도록 공간적인 정보를 최대한 유지 할 수 있다.
- U-Net과 유사하게 intermediate(중급의) Connection을 가지는 Encoder Decoder 구조를 적용하여 보다 정교한 Object Boundary를 에측 할 수 있게 했다.

#### Encoder
- 여기서 Output Stride 개념이 쓰인다, Encoder Output 크기 / Input Image 크기 로 생각 한다. 최종 Feature Map이 Input Image에 비해 32배 줄었다면 Output Stride는 32가 된다.
- Semantic Segmentation에서는 더욱 디테일한 정보를 얻어내기 위해 마지막 부분의 Block의 1개 또는 2개를 삭제함으로써 Output Stride를 16또는 8로 줄인다.
- 또한 Convolution 대신 Atrous Convolution을 사용함으로써 추상화 되지 않는 Feature를 얻어 낼 수 있다.

#### Decoder
- DeepLab V3는 Decoder의 결과를 단순히 Bilinear Upsampling 했다. 
- DeepLab V3는 Decoder의 결과와 Encoder에서 생성한 Low-Level Feature를 Concate하는 과정이 추가 됬다.

## DeepLabV3 Structure
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbDzfwh%2Fbtq1xlJSvg0%2FfiYENhKVTV1UqRCClodMR1%2Fimg.png)
- DeepLab V3는 백본 ResNet을 사용하고 Convolution 연산을 Atrous Convolution 연산으로 수행한다.
- Spatial Pyramid Pooling으로 얻은 Encoder Feature는 1차 적으로 4배 UpSampling 한다.
- 백본에서 상응하는 Low-Level Feature와 Concate 된다.
(이때, 1X1 Convolution을 사용해서 백본의 low-level Features의 채널을 줄여 준다. 그 이유는 Encoder의 채널이 백본의 결과보다 채널수가 작기 때문에 Convoltuion시 중요도를 동일하게 맞춰주기 위해서 이다.)
- Concat 이후에 3X3 Convolution을 통해 Feature를 정교화 시킨 뒤, 4배 Bilinear upsampling을 시켜서 크기를 Input과 동일하게 맞춰 준다.


#### 출처
- [링크 1](https://noteforstudy.tistory.com/entry/DeepLabv3-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0)
- [링크 2](https://cake.tistory.com/41)
- [링크 3](https://deep-learning-study.tistory.com/877)