## Pix2Pix란
- GAN 처럼 Random Vector가 아니라 이미지를 Input으로 받아서 다른 Style의 이미지를 Output으로 출력하는 알고리즘 이다.
- 이를 학습 시키기 위해서는 Input으로 들어갈 Dataset과 그 이미지들이 Pix2Pix를 거쳐서 나올 정답 이미지가 필요하다.
- 즉, Supervised Learning 알고리즘이다.
![image](https://hyeongminlee.github.io/img/GAN_004/fig3.jpg)
- Supervised Learning 알고리즘은 Dataset 구축이 어렵다는 단점이 있으나, 원본 이미지에서 왼쪽 이미지와 같은 이미지를 얻는 것은 쉽다.
- 그렇기 때문에 Supervised Learning 이기는 해도 Dataset 구축이 어렵지 않다.

## Generator
![image](https://hyeongminlee.github.io/img/GAN_004/fig1.png)
- Pix2Pix의 Generator는 전체 적인 구조가 일반적인 Generator 구조와 다르다.
- Input과 Output이 모두 이미지 이기 때문에, 전체 적으로 Size가 줄었다가 다시 커지는 구조이다.
- 이미지를 줄이는 Encoder, 이미지를 키우는 Decoder 구조를 갖는다.
- Size를 줄일 땐 Stride가 2인 Convolution을 이용한다.(Pooling을 사용하지 않는다.)
- Size를 키울 땐 Transposed Convolution을 이용한다.
![image](https://user-images.githubusercontent.com/50395556/81541105-9401e980-93ad-11ea-87a1-a7676fbd8314.png)
- Output Layor의 Activation Function은 tanh를 사용해 -1~1 값을 갖게 한다
- Input 또한 -1~1로 Normalize 해서 넣는다.
- 점선 : Skip Connection
- Encoder와 Decoder 부분이 완벽한 대칭 구조를 이루고 있다.
- Decoder의 각 Output에 대해서 이에 대당하는 Encoder의 Output이 존재 한다.
- Encoder에서 각각 Activation Fuction을 거치기 전의 Output들을 복사하여 Decoder의 Activation Function을 거친 후의 Output에 Concatnate한다. 그대로 뒤에 붙여 준다.
- Encoder-Decoder 구조 단점 중 하나가, 중앙 Feature Dimension이 Input보다 작기 때문에 정보의 손실이 발생 한다는 점이다.
- 그렇기 때문에 Output을 만들때는 Input보다 적은 정보만 가지고 생성 해야 하는 어려 움이 있기 때문에 각 Layer에 정보가 손실되기 전 Encoder단의 Feature를 제공하여 참고하게 만드는 것이다. 
- 이를 통해 더 선명한 Output.을 얻을 수 있고, Skip Connection이 추가된 Encoder-Decoder 형태를 U-Net 구조 라 한다.

## Discriminator
![image](https://hyeongminlee.github.io/img/GAN_004/fig2.png)
- Stride가 2인 Convolution Layer로 구성되어 있다.(따로 Pooling을 하지 않는다.)
- 마지막 두 Layer의 경우 Stride가 1인 Valid Convolution(Padding을 안하는 Convolution)을 통해 최종적으로 30x30의 output을 출력 한다.
- 일반적인 Discriminator의 출력이 0~1 사이의 Scalar(Real/Fake 인지 판단하는 점수) 라는 점을 생각 하면 특이한 부분이다.
- 그 이유는 Discriminate를 이미지의 각 부분별로 진행하기 위함이다.
- 이미지를 통째로 진짜인지 아닌지를 판단하는 것이 아니라, 이미지의 각 부분이 진짜 인지 아닌지를 판별하도록 하는 것이다.
- 이를 통해 좀더 디테일한 부분을 살린 이미지를 얻을 수 있다.
- 원본이미지, Generator 이미지의 Concatenation이 입력이다.

## Training Pix2Pix
- pix2pix는 일반적인 GAN의 Loss에서 하나가 더 추가 된다.
- Output으로 생성한 이미지가 미리 준비된 정답 이미지와 같아야 한다.
- 즉, 예측과 정답 사이의 Distance에 해당하는 Loss가 추가 되야 한다.

#### GAN Loss
![image](GAN-Loss.PNG)

#### Pix2Pix Loss
![image](Pix2Pix-L1-Distance.png)
- 각 픽셀 값의 차이

![image](Pix2Pix-Loss.PNG)
- 각 픽셀 값의 차이 합이 Generator Loss에 추가 된다.