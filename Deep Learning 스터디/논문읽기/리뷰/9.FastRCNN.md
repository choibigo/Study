# Auto Encoder

# Fully Convolution Networks(FCN)

## FCN의 배경
- classification 에서 좋은 성능을 보인 CNN 기반의 딥러닝 네트워크를 Localization이나 Segmentation에 적용 시켜 성능 향상을 해보려는 시도에서 탄생
  
## FCN - Downsampling
![image](https://gaussian37.github.io/assets/img/vision/segmentation/fcn/0.png)
- Classification을 할때, 마지막 FC Later를 Softmax로 출력 하게 되며 확률 값을 나타나게 되며 이 확률 값을 통해 예측된 클래스를 판단 한다.
- Classification 은 물체 위치 정보는 없고 물체가 어떤 물체인지에 대한 확률 값만 가지게 된다. 즉, 물체 위치 정보를 잃어버리게 된다.
- 하지만 입력 값은 이미지 내의 어떤 물체에 대한 **공간 정보**를 가지고 있었고 하위 레벨로 내려가면서도 그 공간 정보를 계속 가지고 있다.
- 공간 정보를 잃어버리는 시점이 바로 ``Fully Connected Layer``이다. 모든 노드 들이 서로 곱한 후 더해지는 형태가 되기 때문이다.
- 따라서 Classifier 용도로 사용한 Fully Connected Layer를 사용 하지 않는다.

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdFCrua%2FbtqBBU4VRCv%2FSUGo2pXb9ERNo935sztYwK%2Fimg.png)
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb2MgcT%2FbtqBzPXN4P5%2FWk5vz6y3KZ5BsK61heOtY1%2Fimg.png)
- 그래서 Fully Connected Layer를 대신 하여 NIN(Network In Network, 1x1 Network)를 사용한다.
  - 1x1 형태의 Convolution 층들로 전환 하면서 위치 정보가 손실 되지 않는다. 
  - 어떠한 입력 이미지의 크기도 허용 할 수 있다.
- class의 Score와 위치정보를 담고 있는 Heatmap을 이용하여 Segmentation을 구현 하게 된다.
- Convolution 층들을 거치고 나서 얻게된 마지막 Heatmap의 개수는 훈련된 Class의 개수와 동일 하다. 즉, 각 Heatmap은 하나의 Class 예측 값을 대표 한다.
- 고양이 class에 대한 Heatmap이라면 고양이가 있는 위치의 픽셀값이 높고 강아지 Class에 대한 Heatmap 이라면 강아지 위치의 픽셀값들이 높다.
- Downsampling 작업은 Encoder 역할을 한것으로 볼 수 있다. 
- 전체적인 구조에서 Layer의 사이즈가 줄었다가 다시 입력 크기로 크게 만들 때, 각 Layer의 Featuer들의 해상도가 다르다. 이것들을 마지막 layer에서 Concat을 통해 성능 개선을 한다.


## FCN - Upsampling
- Downsampling 한 Feature를 이미지 크기만큼 다시 Upsampling 해줘야 한다.
- Bilinear Interpolation 같은 방법으로 할수 있겟지만 성능이 좋지 않다.
- Decoder 단인 Deconvolution 연산에서도 Parameter를 학습 하는 컨셉이다.


## FCN - Skip Connection
![image](https://gaussian37.github.io/assets/img/vision/segmentation/fcn/4.png)
- 가장 왼쪽의 Segmentation 결과는 클래스별로 잘 구분해서 Segmentation 했지만 저해상도와 같이 뭉개져 있다.
- Feature를 Deconvolutino 할 때 사용 할 수 있도록 바로 전달해주는 Skip Connection을 만들어 문제를 개선 한다.
- 대칭되는 네트워크 구조에 따라 단계 별로 Skip Connection이 만들어 성능을 좋게 한다.
![image](https://gaussian37.github.io/assets/img/vision/segmentation/fcn/5.png)
- FCN-32s 는 Pool5에서 Skip 없이 바로 32배 Upsampling 했다.
- FCN-16s 는 Pool5를 2배 Upsampling 한 다음 Pool4와 Sum 을 한 이후 16배 Upsampling 하여 원본 크기로 복원 한다.
- FCN-16s에서 Sum한 결과와 Pool3의 값을 Sum 한 후 8배 Upsampling 하여 원본 크기로 복원 한다.


## FCN 정리
- FCN은 Segmentation을 하기 위한 딥러닝 네트워크 구조로 원본 이미지를 의미 잇는 부분끼리 묶어서 분할 하는 기법이다.
- 픽셀 단위의 Classification이다.



#### 1x1 Convolution
- 필터 크기 : (1 x 1 x input_channel, filter_count )
- filter_count => 1x1 convolution 후 결과 Output Channel


#### 출처
- https://gaussian37.github.io/vision-segmentation-fcn/
- https://github.com/yunlongdong/FCN-pytorch