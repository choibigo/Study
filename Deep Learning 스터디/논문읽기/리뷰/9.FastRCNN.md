# Auto Encoder

# Fully Convolution Networks(FCN)

## FCN의 배경
- classification 에서 좋은 성능을 보인 CNN 기반의 딥러닝 네트워크를 Localization이나 Segmentation에 적용 시켜 성능 향상을 해보려는 시도에서 탄생
  
## FCN - Downsampling
![image](https://gaussian37.github.io/assets/img/vision/segmentation/fcn/0.png)
- Classification을 할때, 마지막 FC Later를 Softmax로 출력 하게 되며 확률 값을 나타나게 되며 이 확률 값을 통해 예측된 클래스를 판단 한다.
- Classification 은 물체 위치 정보는 없고 물체가 어떤 물체인지에 대한 확률 값만 가지게 된다. 즉, 물체 위치 정보를 잃어버리게 된다.
- 하지만 입력 값은 이미지 내의 어떤 물체에 대한 **공간 정보**를 가지고 있었고 하위 레벨로 내려가면서도 그 공간 정보를 계속 가지고 있다.
- 공간 정보를 잃어버리는 시점이 바로 ``Fully Connected Layer``이다. 모든 노드 들이 서로 곱한 후 더해지는 형태가 되기 때문이다.
- 따라서 Classifier 용도로 사용한 Fully Connected Layer를 사용 하지 않는다.

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdFCrua%2FbtqBBU4VRCv%2FSUGo2pXb9ERNo935sztYwK%2Fimg.png)
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb2MgcT%2FbtqBzPXN4P5%2FWk5vz6y3KZ5BsK61heOtY1%2Fimg.png)
- 그래서 Fully Connected Layer를 대신 하여 NIN(Network In Network, 1x1 Network)를 사용한다.
  - 1x1 형태의 Convolution 층들로 전환 하면서 위치 정보가 손실 되지 않는다. 
  - 어떠한 입력 이미지의 크기도 허용 할 수 있다.
- class의 Score와 위치정보를 담고 있는 Heatmap을 이용하여 Segmentation을 구현 하게 된다.
- Convolution 층들을 거치고 나서 얻게된 마지막 Heatmap의 개수는 훈련된 Class의 개수와 동일 하다. 즉, 각 Heatmap은 하나의 Class 예측 값을 대표 한다.
- 고양이 class에 대한 Heatmap이라면 고양이가 있는 위치의 픽셀값이 높고 강아지 Class에 대한 Heatmap 이라면 강아지 위치의 픽셀값들이 높다.
- Downsampling 작업은 Encoder 역할을 한것으로 볼 수 있다. 
- 전체적인 구조에서 Layer의 사이즈가 줄었다가 다시 입력 크기로 크게 만들 때, 각 Layer의 Featuer들의 해상도가 다르다. 이것들을 마지막 layer에서 Concat을 통해 성능 개선을 한다.


## FCN - Upsampling
- Downsampling 한 Feature를 이미지 크기만큼 다시 Upsampling 해줘야 한다.
- Bilinear Interpolation 같은 방법으로 할수 있겟지만 성능이 좋지 않다.
- Decoder 단인 Deconvolution 연산에서도 Parameter를 학습 하는 컨셉이다.


## FCN - Skip Connection
![image](https://gaussian37.github.io/assets/img/vision/segmentation/fcn/4.png)
- 가장 왼쪽의 Segmentation 결과는 클래스별로 잘 구분해서 Segmentation 했지만 저해상도와 같이 뭉개져 있다.
- Feature를 Deconvolutino 할 때 사용 할 수 있도록 바로 전달해주는 Skip Connection을 만들어 문제를 개선 한다.
- 대칭되는 네트워크 구조에 따라 단계 별로 Skip Connection이 만들어 성능을 좋게 한다.
![image](https://gaussian37.github.io/assets/img/vision/segmentation/fcn/5.png)
- FCN-32s 는 Pool5에서 Skip 없이 바로 32배 Upsampling 했다.
- FCN-16s 는 Pool5를 2배 Upsampling 한 다음 Pool4와 Sum 을 한 이후 16배 Upsampling 하여 원본 크기로 복원 한다.
- FCN-16s에서 Sum한 결과와 Pool3의 값을 Sum 한 후 8배 Upsampling 하여 원본 크기로 복원 한다.


## FCN 정리
- FCN은 Segmentation을 하기 위한 딥러닝 네트워크 구조로 원본 이미지를 의미 잇는 부분끼리 묶어서 분할 하는 기법이다.
- 픽셀 단위의 Classification이다.

#### 1x1 Convolution
- 필터 크기 : (1 x 1 x input_channel, filter_count )
- filter_count => 1x1 convolution 후 결과 Output Channel


#### Deconvolution
- https://cumulu-s.tistory.com/29

#### 출처
- https://gaussian37.github.io/vision-segmentation-fcn/
- https://github.com/yunlongdong/FCN-pytorch





# Fast RCNN

![image](FastRCNN-Net.png)

## Learning To Down-Sample
1) Convolution
   1) Convolution
   2) Batch **Normalize**
   3) ReLU
2) Depthwise Separable Convolution Layer 1
3) Depthwise Separable Convolution Layer 2

#### Depthwise Separable Convolution
![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbQ2Tyd%2FbtqUekd4cql%2FuH136XAzs4mGdxeL1nx8bK%2Fimg.png)
- Filter와 연산 결과를 더한 결과를 Feature Map으로 사용한다.

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FRrF3q%2FbtqUmJJ95Bc%2Fh7PeSKNYpUEgTavpcgSxw0%2Fimg.png)
- Filter의 결과를 하나로 합치지 않고 그냥 합쳐 FeatureMap 으로 사용한다.

![image](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbPWkFu%2FbtqUmJQULsO%2FX6F6kUMsksucWk5gXNA8n0%2Fimg.png)
- kernel Size 제곱 만큼의 차이가 발생 한다.
- Standard Convolution 은 K x K x C X M (커널 크기 X 커널 크기 X 입력 채널 X 출력 채널) 만큼의 연산이 필요하다.
- Depth-wise Separable Convolution 은 K X K X C (각 입력 채널 별로 필요로 하는 연산 X 입력 채널) +  1 x 1 X C X M (1x1 으로 bottle neck구조 X 입력 채널 수 X 출력 채널 수)로 K 제곱 만큼의 차이가 있다.

## Global Feature Extrator
- Segmentation을 위한 Global Context를 뽑는 것을 목저으로 한다.
- 1/8 만큼 Downsampling한 Feature를 통해 Global Feature를 뽑는다.
- 
1) bottleneck1
  1) Convolution + Batch Normalize + ReLU
  2) Deep Wise Convolution
  3) Convolution
  4) Batch normalize
2) bottleneck2
   ...
3) bottleneck3
   ...
4) PyramidPolling

#### Bottleneck 
1) 1x1 커널로 채널을 압축한다, 오로지 연산량을 줄이기 위함이다.
2) Convolution 연산을 통해 특징을 추출한다.

#### PyramiodPolling
- 피라미드 크기의 (1x1, 2x2, 3x3, 6x6..) Pooling을 거친 결과를 Concatenation 한다.
- 다른 크기의 영역의 정보를 하나로 취합한다.

## FeatureFusionModule
- Global Feature를 통과한 Feature(Low Level Feature)와 Downsampling 만(High Level Feature) 정보를 합친다.

#### High Level
1) Convolution
2) batchNoramlize

#### Low Level
1) Interpolate
2) DWConvolution
3) Convolution
4) Batch Normalize

- 두 Feature 를 합친 후 결과를 Relu



## Classifier
1) Deepwise Convoltuion1
2) Deepwise Convoltuion2
3) convolution 