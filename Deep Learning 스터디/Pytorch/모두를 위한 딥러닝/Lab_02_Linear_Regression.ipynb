{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5566,"status":"ok","timestamp":1661680017313,"user":{"displayName":"Dae-won Choi","userId":"01176682398277072949"},"user_tz":-540},"id":"YWzaAWzZ19fV","outputId":"6fefacba-33db-4754-be3a-beacbfeea940"},"outputs":[{"name":"stdout","output_type":"stream","text":["Success\n"]}],"source":["# !pip3 install torch\n","# !pip3 install torchvision\n","# !pip3 install matplotlib\n","# !pip3 install torchmetrics\n","\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision\n","from torchvision import datasets\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","print(\"Success\")"]},{"cell_type":"markdown","metadata":{"id":"8wwMYsRb2O72"},"source":["## Definition\n","- 학습 시간에 따른 점수 예측 "]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":664,"status":"ok","timestamp":1661681356381,"user":{"displayName":"Dae-won Choi","userId":"01176682398277072949"},"user_tz":-540},"id":"3Xe19QgU2l-t"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 : Loss = 18.66666603088379\n","2 : Loss = 15.344830513000488\n","3 : Loss = 12.61413288116455\n","4 : Loss = 10.369377136230469\n","5 : Loss = 8.524088859558105\n","6 : Loss = 7.007180690765381\n","7 : Loss = 5.760213375091553\n","8 : Loss = 4.735151290893555\n","9 : Loss = 3.892504930496216\n","10 : Loss = 3.199812650680542\n","11 : Loss = 2.6303882598876953\n","12 : Loss = 2.1622962951660156\n","13 : Loss = 1.7775039672851562\n","14 : Loss = 1.4611867666244507\n","15 : Loss = 1.2011605501174927\n","16 : Loss = 0.9874074459075928\n","17 : Loss = 0.8116928935050964\n","18 : Loss = 0.6672477126121521\n","19 : Loss = 0.5485071539878845\n","20 : Loss = 0.4508974552154541\n","21 : Loss = 0.3706575930118561\n","22 : Loss = 0.3046969473361969\n","23 : Loss = 0.2504744231700897\n","24 : Loss = 0.20590102672576904\n","25 : Loss = 0.16925977170467377\n","26 : Loss = 0.13913899660110474\n","27 : Loss = 0.11437847465276718\n","28 : Loss = 0.0940241813659668\n","29 : Loss = 0.07729215174913406\n","30 : Loss = 0.06353750824928284\n","31 : Loss = 0.05223068594932556\n","32 : Loss = 0.04293586686253548\n","33 : Loss = 0.03529519960284233\n","34 : Loss = 0.029014231637120247\n","35 : Loss = 0.023850908502936363\n","36 : Loss = 0.019606463611125946\n","37 : Loss = 0.01611747033894062\n","38 : Loss = 0.013249230571091175\n","39 : Loss = 0.010891455225646496\n","40 : Loss = 0.008953254669904709\n","41 : Loss = 0.007359976414591074\n","42 : Loss = 0.0060502164997160435\n","43 : Loss = 0.004973519127815962\n","44 : Loss = 0.004088442772626877\n","45 : Loss = 0.0033608966041356325\n","46 : Loss = 0.002762817544862628\n","47 : Loss = 0.0022711530327796936\n","48 : Loss = 0.0018669920973479748\n","49 : Loss = 0.0015347525477409363\n","50 : Loss = 0.001261629513464868\n","51 : Loss = 0.001037116744555533\n","52 : Loss = 0.0008525527082383633\n","53 : Loss = 0.0007008474203757942\n","54 : Loss = 0.0005761170177720487\n","55 : Loss = 0.0004735983384307474\n","56 : Loss = 0.0003893240645993501\n","57 : Loss = 0.0003200455103069544\n","58 : Loss = 0.0002630899252835661\n","59 : Loss = 0.00021627034584525973\n","60 : Loss = 0.00017778044275473803\n","61 : Loss = 0.0001461460633436218\n","62 : Loss = 0.00012013984814984724\n","63 : Loss = 9.875676914816722e-05\n","64 : Loss = 8.118301775539294e-05\n","65 : Loss = 6.673594907624647e-05\n","66 : Loss = 5.485818473971449e-05\n","67 : Loss = 4.509718201006763e-05\n","68 : Loss = 3.7070141843287274e-05\n","69 : Loss = 3.04729474009946e-05\n","70 : Loss = 2.5048773750313558e-05\n","71 : Loss = 2.0592005967046134e-05\n","72 : Loss = 1.692634032224305e-05\n","73 : Loss = 1.391479599988088e-05\n","74 : Loss = 1.1438499313953798e-05\n","75 : Loss = 9.40190875553526e-06\n","76 : Loss = 7.729523531452287e-06\n","77 : Loss = 6.353527624014532e-06\n","78 : Loss = 5.2228529057174455e-06\n","79 : Loss = 4.292800895200344e-06\n","80 : Loss = 3.5290031519252807e-06\n","81 : Loss = 2.900675099226646e-06\n","82 : Loss = 2.385207153565716e-06\n","83 : Loss = 1.9605588477134006e-06\n","84 : Loss = 1.6121160797410994e-06\n","85 : Loss = 1.3248258028397686e-06\n","86 : Loss = 1.0894972319874796e-06\n","87 : Loss = 8.955524322118436e-07\n","88 : Loss = 7.362697829194076e-07\n","89 : Loss = 6.053269885342161e-07\n","90 : Loss = 4.974427270099113e-07\n","91 : Loss = 4.087949037057115e-07\n","92 : Loss = 3.3596597859286703e-07\n","93 : Loss = 2.7631480747913884e-07\n","94 : Loss = 2.2707621383233345e-07\n","95 : Loss = 1.8655379108167836e-07\n","96 : Loss = 1.5321954549563088e-07\n","97 : Loss = 1.2600725085576414e-07\n","98 : Loss = 1.0349058499059538e-07\n","99 : Loss = 8.49806056635316e-08\n","100 : Loss = 6.986899592220652e-08\n","Train End\n","tensor([1.9999], grad_fn=\u003cSubBackward0\u003e)\n","tensor([1.0439e-05], requires_grad=True)\n","tensor([ 2.9998, 18.7990, 20.7989,  1.9999,  3.9998,  5.9997],\n","       grad_fn=\u003cAddBackward0\u003e)\n"]}],"source":["x_train = torch.FloatTensor([[1],[2],[3]])\n","y_train = torch.FloatTensor([[2],[4],[6]])\n","\n","W = torch.zeros(1, requires_grad=True) # requires_grad를 True로 설정해 학습할 것이라 명시\n","\n","# y = Wx\n","# W : weight\n","\n","lr = 0.01\n","\n","epochs = 100\n","for epoch in range(1, epochs + 1):\n","\n","  hypothesis = x_train * W\n","  \n","  cost = torch.mean((hypothesis - y_train)**2) # cost(MSE)  계산\n","  gradient = 2*torch.mean((W * x_train - y_train) * x_train) # cost에 대한 w미분(Loss에 대해 w가 미치는 영향)\n","\n","  W = W - lr*gradient # cost gradient로 W 갱신\n","\n","  if epoch%1 == 0:\n","    print(f\"{epoch} : Loss = {cost}\")\n","\n","print(\"Train End\")\n","\n","inference_data = torch.FloatTensor([1.5, 9.4, 10.4, 1, 2, 3])\n","\n","result = inference_data * W + b\n","\n","print(W)\n","print(b)\n","\n","print(result)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNAcSbZKcaI10cepriS3hbf","collapsed_sections":[],"name":"Lab_02_Linear_Regression.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}