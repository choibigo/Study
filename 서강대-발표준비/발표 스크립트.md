# 1 Page
<img src="https://user-images.githubusercontent.com/38881179/226257072-f156f66e-f239-4665-bd9d-1611318bac5a.PNG" width="500" height="350"/><br>
- 안녕하십니까 과제 발표를 하게된 최대원 이라고 합니다.
- 발표하는 중에 궁금하신 부분이 있다면 바로 말씀해 주시면 감사하겠습니다.

# 2 Page
<img src="https://user-images.githubusercontent.com/38881179/226257076-0613c338-45db-4f81-85f0-d64043f82945.PNG" width="500" height="350"/><br>
- 과제에는 3가지 문제가 있었습니다.
- 첫번째, Sobel Edge Mask를 사용후 Edge Score를 구한 이후, 논-맥시멀 서프레션, 히스테리시스 쓰레스 홀드를 이용하여 더 정확한 엣지를 구하는 문제
- 두번째, 구한 엣지를 바운더리 트레이싱하여 외곽선을 구하는 문제
- 세번째, 딥러닝을 이용하여 엣지를 구하는 문제 입니다.

# 3 Page
<img src="https://user-images.githubusercontent.com/38881179/226257077-2eaf43b6-334e-4d88-a708-89026f49dd66.PNG" width="500" height="350"/><br>
- 첫번쨰 문제의 목차 입니다.
- 엣지의 정의와, 의미
- 소벨 마스크에 대한 정의
- 소벨 마스크를 이용한 컨볼루션
- 논-맥시멀 서브레션
- 히스테리 시스 스레스홀드 입니다.

# 4 Page
<img src="https://user-images.githubusercontent.com/38881179/226257080-cca9346b-337b-43fd-bc4a-40e78bfb6ada.PNG" width="500" height="350"/><br>
- 엣지의 정의 입니다
- 엣지란 밝기 값이 낮은 값에서 높은 쪽으로(또는 그 반대 쪽으로) 급격하게 변하는지점에 존재하는 부분을 의미 합니다.
- 위 그림을 1차 미분 그래프로 본다면 급격하게 변하는 구간이 두군데 존재 합니다.
- 따라서 이 두 군대는 엣지라고 판단할 수 있습니다.

# 5 Page
<img src="https://user-images.githubusercontent.com/38881179/226257082-38c14ed0-b56a-48a2-bae2-3878a6a0d2d5.PNG" width="500" height="350"/><br>
- 좀더 자세하게 보겠습니다.
- 위와같은 그림에을 해당 라인의 Intensity 그래프를 보면 다음과 같습니다.
- 1차 미분을 하게 된다면 Intensity 그래프가 변하는 부분만 값을 갖게 되고 나머지는 0이 됩니다.
- 이러한 1차 미분 값에 대해 임계값을 줘서 Edge를 검출하는 원리가 Sobel Mask를 이용한 방법 입니다.

# 6 Page
<img src="https://user-images.githubusercontent.com/38881179/226257086-7caada8c-20c2-4c84-9d56-0bb8bda41bb6.PNG" width="500" height="350"/><br>
- 1차 미분값을 근사화 하는 방법은 총 3가지가 있습니다.
- forward, backward, 중앙 차분 방법
- Sobel Mask는 중앙 차분을 이용하며 자신의 앞쪽 픽셀과 뒷쪽 펙셀을 빼서 구할 수 있습니다. 이떄 2h는 모두 동일함으로 생략 합니다.
- 이러한 마스크를 8방향과 가중치를 고려하여 3x3 마스크를 만들 수 있습니다.
- X축일 경우 좌우는 큰 가중지 대각선은 더 낮은 가중치를 이용합니다.  
- 해당 실험에서는 3x3 마스크만 이용했지만, 5x5, 7x7등 다양한 크기의 마스크를 이용할 수 있습니다.

# 7 Page
<img src="https://user-images.githubusercontent.com/38881179/226257088-1e675157-292f-461e-8c7f-7d3b9f173926.PNG" width="500" height="350"/><br>
- 위에서 구한 Mask를 이용해 Convolution 연산을 합니다.
- Convolution 그냥 하게 되면 출력 결과가 입력 결과에 비해 작은 크기가 됩니다.
- 이를 방지 하기 위해 Padding을 했으며, Padding Type은 Replicate를 했습니다. 
- Padding된 이미지와 Sobel Mask를 이용하여 1차 미분 Map을 구할 수 있습니다.

# 8 Page
<img src="https://user-images.githubusercontent.com/38881179/226257090-a7ecc0f0-18dc-4906-8a6c-505dfe71155c.PNG" width="500" height="350"/><br>
- 해당 Conovlution 연산을 x방향 마스크, y방향 마스크 2번 수행합니다.
- X, Y 마스크 이후 구해진 1차 미분맵에 절대 값을 취한 이후 더해줘서 Magnitude를 구합니다.
- Magnitude는 X와 Y방향 크기를 모두 가지고있는 Map 입니다.

# 9 Page
<img src="https://user-images.githubusercontent.com/38881179/226257093-255fd353-2571-48f7-a7b5-d3da8a24b5e5.PNG" width="500" height="350"/><br>
- x방향 마스크를 구했기 때문에 세로방향 Edge를 구할 수 있습니다.
- 따라서 세로 나무 무늬가 두드러지게 나타 납니다.
- Object와 Background경계에서 X 방향으로 변화하는 영역만 검출되며, Y 방향으로 변화하는 영역의 값은 작습니다.

# 10 Page
<img src="https://user-images.githubusercontent.com/38881179/226257095-1baff409-26fc-4726-9eb1-026c65bf0a06.PNG" width="500" height="350"/><br>
- Y방향 마스크를 이용한 Convolution 입니다.
- Y방향 마스크를 이용했기 떄문에 세로 나무 무늬를 검출하지 못합니다.
- Object와 Backgroudn 경계에서 Y방향으로 변화하느 영역만 검출 됩니다.

# 11 Page
<img src="https://user-images.githubusercontent.com/38881179/226257096-94004b8f-0086-4535-aef1-1785d70cddb8.PNG" width="500" height="350"/><br>
- 논 맥시멀 슈프레션 입니다.
- 논-맥시멀 슈프레션은 더 얇고 정확한 Edge만 검출하기 위해서 사용하게 됩니다.
- 위에서 구한 Magnitude 즉, Sobel Result를 바로 쓰레스홀드 하게 되면 엣지가 두껍게 나타나게 됩니다.
- 이를 방지 하기 위해 논-맥시멀 슈프레션을 하게됩니다.

# 12 Page
<img src="https://user-images.githubusercontent.com/38881179/226257099-78954ce1-affc-4aad-835d-eb5001b6b918.PNG" width="500" height="350"/><br>
- 논-맥시멀 슈프리션은 말그대로 최대치가 아닌 값들에 대해 억제 하는 알고리즘입니다.
- 왼쪽 영역을 Edge Detection 했을 때 Edge가 두껍게 나타나는 것이 아는 해당 영역의 가장 큰 값들만 Edge로 나타나기를 원합니다.

# 13 Page
<img src="https://user-images.githubusercontent.com/38881179/226257101-89798aca-728f-47de-b017-6126ee900617.PNG" width="500" height="350"/><br>
- 전체적인 알고리즘에 대한 설명 입니다.
- sobel X, Y 마스크를 통해 얻은 Map으로 Gradient의 방향을 분석할 수 있습니다.
- 이러한 방향을 통해 해당 방향에 있는 픽셀 값과 비교하여 그 영역중 가장 크다면 살리고 그렇지 않다면 역제 합니다.
- 이후 Threshold를 하여 단일 Edge를 검출할 수 있습니다.

# 14 Page
<img src="https://user-images.githubusercontent.com/38881179/227749801-cd629491-f884-41c5-8a6c-b81f0ddf57f9.PNG" width="500" height="350"/><br>
- 첫번째 Phase를 구하는 방법 입니다.
- 저희는 X방향 Gradient와 Y방향 Gradient를 알고 있습니다.
- 이를 이용하여 해당 픽셀의 방향을 알 수 있습니다
- 방향의 각을 θ 라고 했을때 tan(θ)는 Y Gradient / X Gradient 입니다.
- 각을 알기 때문에 방향을 알 있습니다.

# 15 Page
<img src="https://user-images.githubusercontent.com/38881179/226257105-9883f106-216e-4f0f-ad9d-8e505d8b178c.PNG" width="500" height="350"/><br>
- 해당 각에 따라 크게 4가지 그룹으로 나눕니다.
- 그이유는 픽셀의 비교 방향은 크게 8 방향이며 대칭이 되는 방향을 하나의 그룹으로 묶으면 4가지 그룹으로 나눌 수 있습니다.

# 16 Page
<img src="https://user-images.githubusercontent.com/38881179/226257106-54fefc5b-d7e7-428f-920e-3e7cc0fa3501.PNG" width="500" height="350"/><br>
- 해당 픽셀의 각의 그룹에 해당하는 픽셀들과 비교하여 그룹중 가장 크다면 살리고, 그렇지 않다면 억제 즉, 0으로 변경 합니다.
- 이러한 과정을 통해 단일 Edge를 구할 수 있습니다.

# 17 Page
<img src="https://user-images.githubusercontent.com/38881179/226257107-ced32fba-4a3e-4177-a08d-fefb67e17fe8.PNG" width="500" height="350"/><br>
- 오른쪽 그림은 픽셀을 그룹에 따라 시각화 한 것입니다.
- 회색 영역은 135도와 315도 를 그룹으로 한 것입니다.
- 입력이미제에 대해 회색 영역을본다면 방향은 파랑색 화살표로 볼 수 있으며 엣지는 이에 수직인 방향 입니다.
- 이렇게 영역은 두변 영역과 함께 두껍게 나타 나며 비교를 통해 maximal 영역만 살릴 수 있습니다.

# 18 Page
<img src="https://user-images.githubusercontent.com/38881179/226257108-21941635-3500-41bc-a35d-8dbc1dba048c.PNG" width="500" height="350"/><br>
- Sobel 결과로 나온 데이터를 논-맥시멀 슈프리션 알고리즘 수행한 결과 입니다.

# 19 Page
<img src="https://user-images.githubusercontent.com/38881179/227749808-31202865-a662-4dff-b370-c4d8d777c90a.PNG" width="500" height="350"/><br>
- 논-맥시멀 슈프리션 알고리즘 이후 Threshold을 수행하게 됩니다.
- 단일 임계값의 Threshold를 하게 된다면 한계점이 있습니다.
- 왼쪽 Gradient Map의 왼쪽아래 영역을 Edge로 포함하고 싶지 않아 Threshold를 높인다면
- Edge로 찾고 싶은 영역 또한 제거 됩니다. 즉, 주변 영역을 고려하지 않고 자신의 Pixel 값만 보고 판단하면 Edge Detection에 한계가 생깁니다.
- 이를 해결하기 위해 주변 픽셀도 함께 고려할 수 있는 히스테리시스 Threshold를 사용합니다.
- 이를 통해 왼쪽 필요 없는 영역은 제거 되고 Edge로 남기고 싶은 영역은 살릴수 있습니다.
- Edge란 하나씩 나타 나지 않고 연결되어 나타나는 성질을 이용한 것이 히스테리시스 Threshold입니다. 

# 20 Page
<img src="https://user-images.githubusercontent.com/38881179/227749809-06254906-84e6-42f9-8f93-fa2ce20b10d0.PNG" width="500" height="350"/><br>
- 히스테리시스 스레스 홀드는 Upper와 Lower 2개의 임계값을 파라미터로 사용합니다.
- 알고리즘 첫번째 단계 입니다.
- Upper 이상의 값을 가지는 Gradinet 는 Strong Edge로 선별 됩니다.

# 21 Page
<img src="https://user-images.githubusercontent.com/38881179/227749810-bfa9cc34-2a3b-41be-9d2c-4bd9080ea318.PNG" width="500" height="350"/><br>
- Lower 이상 Upper 이하의 Gradient 값에 대한 로직 입니다.
- 해당 구간에 해당하는 픽셀이 Strong Edge와 8방향성을 고려하여 연결 되어 있다면 Edge로 판단 하고 그렇지 않다면 Edge로 판단하지 않습니다.
- 이렇게 Edge로 판단한 픽셀을 Weak Edge라고 합니다.

# 22 Page
<img src="https://user-images.githubusercontent.com/38881179/227749812-e9411996-069e-4d44-bba6-0952947479ab.PNG" width="500" height="350"/><br>
- 최종적으로 Strong Edge와 Weak Edge영역 모두 Edge 로 판별 됩니다.

# 23 Page
<img src="https://user-images.githubusercontent.com/38881179/226257121-797116a5-8781-46c9-b283-2113ae7d5e7d.PNG" width="500" height="350"/><br>
- 히스테리시스 Treshold를 그래프로 보겠습니다.
- 해당 그래프에서 Upper 이상 값을 가지는 영역은 Strong Edge로 판별 합니다.

# 24 Page
<img src="https://user-images.githubusercontent.com/38881179/226257122-efb99840-35be-414b-a6ad-dc90e90a4d2f.PNG" width="500" height="350"/><br>
- Lower이상 Upper 이하의값에 해당하는 영역은 Strong Edge와 연결 되면 Weak Edge로 판별 합니다.
- Strong Edge와 연결되어 있지 않으면 Edge로 판별하지 않습니다.
- 해당 그래프는 모든 Weak Edge가 Strong Edge와 연결되어 있습니다.
- Lower 이하의 값들은 Edge로 판단하지 않습니다.

# 25 Page
<img src="https://user-images.githubusercontent.com/38881179/226257123-072d4336-87b6-406a-ad98-fc125df0bc00.PNG" width="500" height="350"/><br>
- 몇가지 그래프에 대해 Edge 판별 영역을 보겠습니다.
- 첫번째 그래프는 모든 Lower ~ Upper 사이 영역이 Strong Edge와 연결되어 Edge로 판별 됩니다.
- 두번째 그래프의 경우 Lower ~ Upper 사이 영역이 Strong Edge와 연결되어 있지 않기 때문에 Edge로 판별하지 않습니다.
- 세번쨰 그래프의 경우 모든 영역이 Edge 영역으로 판별 됩니다.

# 26 Page
<img src="https://user-images.githubusercontent.com/38881179/226257124-249421e2-b9e4-434b-8be4-79a1a8053fa9.PNG" width="500" height="350"/><br>
- 왼쪽은 입력, 가운데는 논-맥시멀 슈프리션, 오른쪽은 히스테리시스 Threshold 결과 입니다.
- lower가 100 이고 upper가 200 일때 결과 입니다. 노란색, 파란색 영역 모두 Weak Edge가될 수 있는 후보들 입니다.
- 노란색 영역의 값이 파란색 영역의 값보다 크지만 Strong Edge에 연결되어 있지 않기 때문에 Edge로 선택되지 않았습니다.
- 파란색 영역의 값은 노란색 영역보다 작지만 Strong Edge와 연결되어 있기 때문에 Edge로 선택되었습니다. 

# 27 Page
<img src="https://user-images.githubusercontent.com/38881179/226257127-a5a06225-c518-4f91-ba50-383a3834cc14.PNG" width="500" height="350"/><br>
- 히스테리 시스 Threshold결과 는 Edge가 얇게 나타나는 것을 확인할 수 있습니다.
- 11page 일반적인 Threshold를 사용했을 때와 확연한 차이가 있는 것을 확인할 수 있습니다.

# 28 Page
<img src="https://user-images.githubusercontent.com/38881179/226257129-18bfec2e-a060-4433-9ec4-2eede1a05f96.PNG" width="500" height="350"/><br>
- 2번제 문제 Boundary Tracing의 해담 Moore Neighborhood Tracing 입니다.

# 29 Page
<img src="https://user-images.githubusercontent.com/38881179/226257131-cb116d9b-ca1e-4828-9f0a-ab6403227c9e.PNG" width="500" height="350"/><br>
1) 0이아닌 Seed Point 부터 탐색 하며 그점을 fx, fy라고 하며 Boundary List에 그점을 추가 한다.
2) fx, fy-1부터 탐색을 시작하며 1시 방향을 시작으로 시계 방향으로 탐색한다. 이때 필셀주변 8방향을 탐색한다.
3) 탐색중 0이 아는 값을 찾으면 Boundary List에 추가하고, 직전에 탐색된 픽셀과 비교하여 다음 탐색 방향을 설정한다, 찾아 졌던 방향부터 시계 방향으로 탐색한다.
4) 0이 아닌 값이 없으면 종료 한다.
5) 탐색된 값이 이미 Boundary List에 있으면 종료 한다.
6) 알고리즘이 종료 될 때까지 2 ~ 5 단계를 반복한다.

- 전체 적인 알고리즘에 대한 내용입니다. 글만 보면 이해하기 어렵기 때문에 그림과 같이 한단계씩 보도록 하겠습니다. 

# 30 Page
<img src="https://user-images.githubusercontent.com/38881179/226257132-b30f8e47-dd83-4b3c-bc88-927180d47a57.PNG" width="500" height="350"/><br>
- 첫번째, Boundary Tracing을 시작할 Seed Point를 결정 합니다.
- 해당 그림에서는 나사의 최외각선을 따기 위해서 적절한 Seed Point를 설정했습니다.

# 31 Page
<img src="https://user-images.githubusercontent.com/38881179/226257134-e3adb439-1a73-40c4-8f58-caa997197b56.PNG" width="500" height="350"/><br>
- 0이 아닌 Seed Point는 노란색 외각을 가진 픽셀 입니다.
- 그렇기 때문에 시작은 y-1인 빨간색 픽셀 부터 시작을 합니다.
- 오른쪽 그림과 함께 보자면 노란색 픽셀은 빨간색 픽셀로 부터 1번방향 으로 탐색 됐습니다. 
- 그러므로 다음 탐색시 1번 방향부터 탐색을 시작합니다.

# 32 Page
<img src="https://user-images.githubusercontent.com/38881179/226257136-950d6865-3d17-4679-90f1-ca92e1da2f9d.PNG" width="500" height="350"/><br>
- 찾아진 영역은 Boundary List에 추가가 됩니다.
- 다음 픽셀을 찾을 때는 1번 방향 부터 2, 3 번 방향으로 탐색을 시작합니다.
- (이전 페이지를 가서) 그림과 같이 1번 방향부터 2번 방향 마지막 8번 방향까지 탐색 순서 와 방향입니다.

# 33 Page
<img src="https://user-images.githubusercontent.com/38881179/226257137-9f3b1ad7-cd1e-4236-affd-568bf3ec3157.PNG" width="500" height="350"/><br>
- 그 다음 픽셀도 마찬 가지로 1번 방향으로 부터 찾아 졌으므로 1번 방향 부터 탐색을 시작 합니다.
- 그다음 픽셀또한 1번 방향부터 탐색을 시작 하나 4번 까지 가서 탐색이 종료 됬습니다.

# 34 Page
<img src="https://user-images.githubusercontent.com/38881179/226257139-3c620e9f-ff86-40c5-9a43-5e75a6017261.PNG" width="500" height="350"/><br>
- 이런 식으로 1번 (직전 찾아진 픽셀을 가르키며) 여기까지는 모두 1번 방향으로 찾아 진 픽셀들 입니다.
- 다음 픽셀은 3번 방향으로(오른쪽에서 왼쪽 방향으로) 피셀이 탐색 됬습니다.
- 그러므로 3번 방향부터 시작하여(왼쪽에서 오른쪽 방향) 탐색을 시작 합니다.
- 다음 픽셀도 마찬가지로 3번 방향 으로 탐색이 됬습니다.

# 35 Page
<img src="https://user-images.githubusercontent.com/38881179/226257142-ca9d3736-b6a3-41ba-ba30-57ad69ffcff4.PNG" width="500" height="350"/><br>
- 해당 픽셀은 5번 방향(아래에서 위 방향)으로 탐색이 됬습니다. 
- 그렇기 때문에 위에서 아래로 탐색을 먼저 시작해서 다음 Boundary Point를 찾습니다.
- 마지막으로 찾아진 픽셀은 7번 방향 (왼쪽에서 오른쪽 방향)으로 찾아 졌으므로 오른쪽에서 왼쪽으로 탐색을 시작해서 다음 0이아닌 픽셀을 찾습니다.
- 다음 0 이아닌 픽셀이 이미 Boundary List에 존재 함으로 알고리즘을 종료 합니다.

# 36 Page
<img src="https://user-images.githubusercontent.com/38881179/226257143-2d536cb5-bbd9-4473-a9f4-dff1d746990d.PNG" width="500" height="350"/><br>
- 결과 이미지 입니다. 해당 Binary 이미지에서 Seed Point로 부터 Moore Neighborhood Tracing을 수행했을때 Boundary List를 시각화 한 것입니다.
- Object의 최외각 선을 잘 따진것을 볼 수 있습니다.
- Moore Neighborhood Tracing 의 알고리즘은 제대로 수행했습니다. 
- 그러나 OpenCV의 findContour API를 수행하면 Seed Point를 넣지 않고 이미지만 넣고 Object간 위상 관계를 해석하여 Boundary를 찾을 수 있습니다.
- 같은 동작을 하도록 API를 구성하려 헀으나 아직 제가 부족해 동일하게 동작하도록 구성하지 못했습니다. 

# 37 Page
<img src="https://user-images.githubusercontent.com/38881179/226257144-baea8c82-ba95-483a-9d9d-ef0f98056f2e.PNG" width="500" height="350"/><br>
- 세번쩨 문제는 딥러닝을 기반으로 하는 Edge Detection을 수행하는 문제였습니다.
- 저는 홀리스티켈리 네스티드 Edge Detection으로 해결 했습니다, 줄여서 HED라고 하겠습니다.

# 38 Page
<img src="https://user-images.githubusercontent.com/38881179/226257147-ab0ddf72-7ce0-432b-a1e9-40a92408cae6.PNG" width="500" height="350"/><br>
- 전체적인 구성 입니다. 
- 네트워크 Layer별로 나온 Feature Map을 시각화 하여 그 Side-Output을 Concatenation 하여 최종 Output을 만드는 방식입니다.
- Layer별로 나온 Side-Output은 각 Receptive Filed Size가 다릅니다. 이렇게 여러 관점에서 바라본 Side-Output을 합쳐서 최종 Output을 만드는 것 입니다.
- 그림은 해당 논문에 있는 그림 입니다. 

# 39 Page
<img src="https://user-images.githubusercontent.com/38881179/226257149-9e59d887-b52c-4a18-9da0-d5e0a083c62e.PNG" width="500" height="350"/><br>
- Receptive Field란 하나의 Feature가 Input 이미지에 대한 정보를 얼마나 가지고 있나 입니다.
- Kernerl Size 3일때 Input의 초록색 박스는 1번 Convolution 하면 1개의 Feature가 됩니다. 
- 이런식으로 입력의 5x5 영역은 1번째 Layer에서는 3x3 영역으로 압축되며 이때, Receptive Field Size는 3이 됩니다.
- 첫번째 Layer에서 나온 결과를 한번더 3x3 Kernel로 Convolution 하면 1개의 Feature가 Input 에 대해서 5x5 영역의 정보를 압축하고 있습니다.
- 그렇기 때문에 Receptive Field Size는 5가 됩니다. 

# 40 Page
<img src="https://user-images.githubusercontent.com/38881179/226257150-a8c22a92-bf0c-450d-ba17-40073fa55653.PNG" width="500" height="350"/><br>
- 좀더 자세히 HED를 보겠습니다. 
- HED는 VGG 네트워크를 기반으로 설계됬습니다.
- 왼쪽에 나온 표는 VGG 네트워크와 동일 합니다.
- 하지만 HED는 Classifier는 사용하지 않을 것이므로 VGG네트워크에서 제거 해서 사용합니다.
- VGG는 총 5개의 Layer가 존재 합니다. 각 Layer에서 나은 Feature를 이용하여 Side-Output을 만듭니다.
- Layer의 Output은 1채널이 아니기 때문에 1채널을 만들기 위한 Convolution을 첫번째로 수행 합니다.
- 각 Layer에서 나온 Feature는 Receptive Field Size가 5, 14, 40, 92, 196을 갖게 됩니다.
- 이후 Concatenation 하기 위해서 Feature의 사이즈를 맞춰 줍니다. 이때 Binlinear를 이용하여 Upsamling을 수행합니다.
- 그 결과 각 Feature는 입력 이미지와 동일한 사이즈의 크기를 갖습니다.

# 41 Page
<img src="https://user-images.githubusercontent.com/38881179/226257152-26031149-c44c-4f0f-8cfa-e3747f1b1143.PNG" width="500" height="350"/><br>
- Bilinear에 대한 설명입니다.
- 3x3 영역을 7x7 영역으로 만들기 위해 즉, 이미지를 키울때 사용합니다.

# 42 Page
<img src="https://user-images.githubusercontent.com/38881179/226257154-3986f0be-1647-4106-94fd-893353312f22.PNG" width="500" height="350"/><br>
- 아까 그림의 오른쪽 아래 영역만 그린것 입니다. 
- Bilinear Interpolation을 이용하여 별 픽셀의 값을 구해보겠습니다.
- 첫번째 양쪽 유효 픽셀과 얼만큼 떨어져 있나 계산 하여 그 비율을 구합니다.
- 이떄 P 영역은 2/3, 1/3 비율만큼 떨어져 있습니다.
- 그런후 유효 픽셀을 비율만큼 곱해줘서 P값을 구합니다.
- 동일한 방법으로 Q값도 구할수 있습니다.
- 마지막으로 별 픽셀 값을 구하기 위해 P와 Q에 떨여져 있는 비율을 구하고 P와 Q 값을 비율만큼 곱하여 최종적인 값을 구할 수 있습니다.

# 43 Page
<img src="https://user-images.githubusercontent.com/38881179/226257157-8dd8a625-08e4-42c0-8008-9822866cff20.PNG" width="500" height="350"/><br>
- Bilinear Interpolation에 대한 설명 이였습니다.
- 직전에 Interpolation 하여 Feature의 크기를 모두 동일하게 맞춰 줬습니다.
- 이렇게 동일하게 맞춘 Feature를 5개의 채널이 되도록 합친 이후 Convolution 연산을 통해 동일한 높이나 너비를 가지고 채널이 1인 Fuse를 만듭니다.
- 이 Fuse가 최종적으로 얻고 싶은 Feature입니다.

# 44 Page
<img src="https://user-images.githubusercontent.com/38881179/226257158-5411d009-6f97-41f5-b3ca-c3c03d19b16d.PNG" width="500" height="350"/><br>
- HED의 Loss를 구하는 방법 입니다.
- 저희는 앞 단계에서 최종적인 Fuse를 구하여 총 6개의 Feature Map을 알고 있으며 이 모두를 Loss를 구하는데 이용합니다.
- 각 Feature Map을 픽셀 단위로 Sigmoid 활성화 계층을 통과 시킵니다, 이는 각 픽셀을 0인지 1인지 Binary Classification이라고 생각할수 있기 때문입니다.
- Sigmoid를 통과한 Feature와 Edge Ground Truth를 비교하여 Weighted Cross-Entropy를 수행 합니다.
- Feature별로 Loss가 있으며 이것을 합친것이 최종적인 Loss가됩니다.

# 45 Page
<img src="https://user-images.githubusercontent.com/38881179/226257161-fa796e21-99e1-4c73-8b97-3be408741ebd.PNG" width="500" height="350"/><br>
- Weighted Cross Entropy에 대한 설명입니다.
- Loss를 계산할때 배경이 너무 많거나, Edge가 너무 많거나 해서 Class가 Imbalance 할때 사용되는 기법 입니다.
- 더 적은 Class에 더많은 Weight를 줘서 Binary Cross Entropy를 수행 합니다.

# 46 Page
<img src="https://user-images.githubusercontent.com/38881179/226257165-8ddc993b-81b4-4c7c-a472-4d3d970cd463.PNG" width="500" height="350"/><br>
- 더 적은 Class에 더많은 Weight를 줘서 Binary Cross Entropy를 수행 합니다.

#### 44 Page로 돌아가서
- 이렇게 Loss를 구한 이후 학습을 진행 합니다.

# 47 Page
<img src="https://user-images.githubusercontent.com/38881179/227749818-4e35db47-1c40-4cce-9309-88edcde2ef57.PNG" width="500" height="350"/><br>
- 저는 BSD 데이터 셋을 이용했습니다.
- 해당 데이터 셋은 자연 이미지와 Edge 영역 이미지가 쌍으로 존재하는 데이터 셋입니다.
- 이 데이터셋을 이용하여 학습을 진행후 모델 파일을 얻습니다.

# 48 Page
<img src="https://user-images.githubusercontent.com/38881179/226257168-02a924f0-1736-4ced-a139-16c75f2ca8ce.PNG" width="500" height="350"/><br>
- Inference를 할때는 추론하고 싶은 입력 데이터를 입력합니다.
- 모델은 side-output 1~5과 함께 Fuse까지 총 6개의 Output을 내놓습니다.
- 최종적인 Output은 Fuse만 사용하면 됩니다.

# 49 Page
<img src="https://user-images.githubusercontent.com/38881179/226257170-bd792ab1-bdc4-4b3e-bc66-381c55168f65.PNG" width="500" height="350"/><br>
- 처음 Side Output은 RF가 모두 다르다고 했습니다.
- 이를 연속적으로 보면 어떤 의미인지 바로 아실수 있습니다.
- Layer가 깊어 질 수록 더 넓은 영역을 바라 보고 있어서 Edge 영역이 매우 두껍게 잡히는 것을 볼수 있습니다.
- 이렇게 RF를 여러 관점에서 바라 본 후 계속 Edge로 잡히는 영역만 Edge로 판단 합니다.

# 50 Page
<img src="https://user-images.githubusercontent.com/38881179/226257175-a71cb240-a033-483f-8867-616eeb37b441.PNG" width="500" height="350"/><br>
- 각 Output의 Average Precision 입니다.
- Precision은 실제 True 인것들중에 True라고 판단한 비율 입니다.
- Side Output에 각 AP는 Fuse보다 낫습니다.
- RF의 사이즈 와 AP가 어떤 상관관계가 있을것이라 생각했으나 그런 관계는 없고 이미지마다 다르게 나타나는 것을 확인 했습니다.
- 결과적으로 Fuse의 AP가 가장 높게 나타 납니다.
- 실제 이미지를 봐도 Edge를 가장 잘 찾은것을 확인할 수 있습니다.

# 51 Page
<img src="https://user-images.githubusercontent.com/38881179/226257177-6eff187c-3662-44cf-bdd6-a91dd10e88c3.PNG" width="500" height="350"/><br>
- 앞에서 Sobel 을 이용한 Edge Detection과 비교한 이미지 입니다.
- HED를 이용한 배경이나, Object 내부 작은 영역들은 Detection하지 않습니다.
- Object와 Background의 주요 경계선만검출 하는 것을 알수 있습니다.
- 이 Edge들은 비교적 두껍게 찾아 지며 앞에서 수행한 논-맥시멀 슈프리션을 수행하여 얇게만들수 있지 않을까 라는 생각을 했습니다.

# 52 Page
<img src="https://user-images.githubusercontent.com/38881179/226257178-67297d37-25d7-4ebc-81ef-1c8280dc429d.PNG" width="500" height="350"/><br>
- 제 발표는 여기 까지입니다.
- 긴발표 들어주셔서 감사합니다.